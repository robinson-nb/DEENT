{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfb3jM4seBZ9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorboard as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wr0BERMdIRr",
        "outputId": "203da805-2a9c-41f8-bb7d-1763f3613af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "#torch version --> 2.4.1+cu121\n",
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUy2BWgqFi57"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, EarlyStoppingCallback\n",
        "\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk1BaeEbdmQw",
        "outputId": "e87dd0cf-5ffe-4419-b1d3-051000aee4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 123984 entries, 0 to 123983\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   text            123984 non-null  object \n",
            " 1   depression      123984 non-null  float64\n",
            " 2   not_depression  123984 non-null  float64\n",
            " 3   cluster         123984 non-null  int64  \n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/labeled_twitter_depressive_full_clean_km2.csv')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3NP2_kEdqXe"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "X = df['text'].values.tolist()\n",
        "y = df['cluster'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gglmSECrdvRY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LMQ2Kjw3FtZk",
        "outputId": "3fbca572-8443-4a8a-ca42-e71f83f8a2ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvS3zEnL1DMe",
        "outputId": "a107eab5-96d5-40d8-a180-2e22b6977e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tiya1012/swmh4_mtb and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"tiya1012/swmh4_mtb\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
        "model = model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XdwgPHIEcSR",
        "outputId": "67ebb772-54f3-40ec-f1d6-1bd4a4cf2e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train & validation texts encoded\n"
          ]
        }
      ],
      "source": [
        "train_encodings = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "print('Train & validation texts encoded')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDk1hfgy5cQX",
        "outputId": "39209fc2-fa9a-4673-f7b6-194a3525e893"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "test_encodings.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gluPHQpg1PEQ",
        "outputId": "abede157-3531-458a-ebc3-fe70fc8e9461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Class to store the tweet data as PyTorch Dataset\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class TweetDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Class to store the tweet data as PyTorch Dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # an encoding can have keys such as input_ids and attention_mask\n",
        "        # item is a dictionary which has the same keys as the encoding has\n",
        "        # and the values are the idxth value of the corresponding key (in PyTorch's tensor format)\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "print(TweetDataset.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkKSMg7qENLA"
      },
      "outputs": [],
      "source": [
        "train_dataset = TweetDataset(train_encodings, y_train)\n",
        "test_dataset = TweetDataset(test_encodings, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtOXRYNO5cQY"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn as nn\n",
        "\n",
        "# Definir la función de pérdida ponderada\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onT0qnQY5cQY"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "# Definir una clase personalizada para el modelo, sobrescribiendo el método 'compute_loss'\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "import json\n",
        "\n",
        "# Callback personalizado para guardar métricas de entrenamiento y validación\n",
        "class SaveAllMetricsCallback(TrainerCallback):\n",
        "    def __init__(self, output_file=\"metrics.json\"):\n",
        "        self.output_file = output_file\n",
        "        self.metrics = []\n",
        "\n",
        "    def on_log(self, args, state, control, **kwargs):\n",
        "        # Guardar las métricas en cada log\n",
        "        if state.log_history:\n",
        "            # Captura el último registro de métricas\n",
        "            last_log = state.log_history[-1]\n",
        "            # Asegúrate de que las métricas de computación estén incluidas\n",
        "            self.metrics.append(last_log)\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        # Al final del entrenamiento, guardar todas las métricas en un archivo JSON\n",
        "        with open(self.output_file, \"w\") as f:\n",
        "            json.dump(self.metrics, f, indent=4)"
      ],
      "metadata": {
        "id": "D8QJEkK_QaO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar el callback para guardar todas las métricas\n",
        "all_metrics_callback = SaveAllMetricsCallback(output_file=\"all_training_metrics.json\")"
      ],
      "metadata": {
        "id": "OE6OWlF-Qf-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymA7PO_LEzHh"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import accuracy_score, precision_recall_fscore_support, balanced_accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    balanced_acc = balanced_accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds),\n",
        "    recall = recall_score(labels, preds),\n",
        "    f1 = f1_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'balanced_acc' : balanced_acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAI-FqnLEzAx",
        "outputId": "1e245006-5b20-47e2-9f95-e94f6d72dd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    learning_rate=1.5e-4,\n",
        "    lr_scheduler_type=\"linear\",      # Usar scheduler lineal\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.\n",
        "    dataloader_pin_memory=False,     # Whether you want to pin memory in data loaders or not. Will default to True\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    #evaluation_strategy=\"steps\",\n",
        "    #logging_steps=100,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\",  # Desactivar wandb\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "F8vumgYbfyWZ",
        "outputId": "e685e277-c163-41e9-8610-9e5287365ab0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17050' max='77500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17050/77500 4:30:47 < 16:00:13, 1.05 it/s, Epoch 11/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Balanced Acc</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.381000</td>\n",
              "      <td>0.374045</td>\n",
              "      <td>0.838085</td>\n",
              "      <td>0.833462</td>\n",
              "      <td>(0.8202915228231684,)</td>\n",
              "      <td>(0.7998129967274428,)</td>\n",
              "      <td>0.809923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.381125</td>\n",
              "      <td>0.836875</td>\n",
              "      <td>0.826988</td>\n",
              "      <td>(0.85,)</td>\n",
              "      <td>(0.7550257129499767,)</td>\n",
              "      <td>0.799703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.531665</td>\n",
              "      <td>0.831834</td>\n",
              "      <td>0.827176</td>\n",
              "      <td>(0.8124102269462798,)</td>\n",
              "      <td>(0.7932678821879383,)</td>\n",
              "      <td>0.802725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.537011</td>\n",
              "      <td>0.827398</td>\n",
              "      <td>0.824179</td>\n",
              "      <td>(0.799402594978064,)</td>\n",
              "      <td>(0.800748013090229,)</td>\n",
              "      <td>0.800075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.316200</td>\n",
              "      <td>0.701322</td>\n",
              "      <td>0.431302</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>(0.4313021736500383,)</td>\n",
              "      <td>(1.0,)</td>\n",
              "      <td>0.602671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.653800</td>\n",
              "      <td>0.603603</td>\n",
              "      <td>0.612090</td>\n",
              "      <td>0.656679</td>\n",
              "      <td>(0.5270188830855765,)</td>\n",
              "      <td>(0.9812061711079944,)</td>\n",
              "      <td>0.685725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.562700</td>\n",
              "      <td>0.625797</td>\n",
              "      <td>0.588378</td>\n",
              "      <td>0.636249</td>\n",
              "      <td>(0.5118596286575289,)</td>\n",
              "      <td>(0.9846657316503039,)</td>\n",
              "      <td>0.673574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.695400</td>\n",
              "      <td>0.696635</td>\n",
              "      <td>0.431302</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>(0.4313021736500383,)</td>\n",
              "      <td>(1.0,)</td>\n",
              "      <td>0.602671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.695400</td>\n",
              "      <td>0.693289</td>\n",
              "      <td>0.431302</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>(0.4313021736500383,)</td>\n",
              "      <td>(1.0,)</td>\n",
              "      <td>0.602671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.695000</td>\n",
              "      <td>0.696481</td>\n",
              "      <td>0.431302</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>(0.4313021736500383,)</td>\n",
              "      <td>(1.0,)</td>\n",
              "      <td>0.602671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.695200</td>\n",
              "      <td>0.693178</td>\n",
              "      <td>0.568698</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>(0.0,)</td>\n",
              "      <td>(0.0,)</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17050, training_loss=0.4809161593976958, metrics={'train_runtime': 16249.0832, 'train_samples_per_second': 305.208, 'train_steps_per_second': 4.769, 'total_flos': 4.877932970572003e+16, 'train_loss': 0.4809161593976958, 'epoch': 11.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=10)\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,  # training arguments, defined above\n",
        "    train_dataset=train_dataset,  # training dataset\n",
        "    eval_dataset=test_dataset,  # evaluation dataset\n",
        "    compute_metrics=compute_metrics,  # The function that will be used to compute metrics at evaluation\n",
        "    callbacks=[all_metrics_callback, early_stopping]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "PiLEDX9-Ey5A",
        "outputId": "1190af2d-41e0-4c32-da82-68caed4b1d0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='388' max='388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [388/388 01:57]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Evaluar el modelo\n",
        "results = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao6ESvjzg0jj"
      },
      "outputs": [],
      "source": [
        "#trainer.save_model('./best_model2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wNqdj_4g71D",
        "outputId": "c43e3604-6db2-4541-c760-00c4f40f14ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados: {'eval_loss': 0.3740449547767639, 'eval_accuracy': 0.8380852522482558, 'eval_balanced_acc': 0.8334620224028648, 'eval_precision': (0.8202915228231684,), 'eval_recall': (0.7998129967274428,), 'eval_f1': 0.8099228329309284, 'eval_runtime': 117.9486, 'eval_samples_per_second': 210.236, 'eval_steps_per_second': 3.29, 'epoch': 11.0}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Resultados: {results}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg68w41nx2BX"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfgL33uu3Lk9"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'best_mtb_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnF4vPjjCOZh"
      },
      "source": [
        "#Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNixivBo9xf3",
        "outputId": "8e295343-ec4c-4146-a792-d34fd60e7a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at tiya1012/swmh4_mtb and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-24-17ad1ca50338>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_load.load_state_dict(torch.load('best_mtb_model.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"tiya1012/swmh4_mtb\"\n",
        "\n",
        "model_load = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
        "model_load.load_state_dict(torch.load('best_mtb_model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Lr_jziAbrB",
        "outputId": "6d82f9ad-3159-4f36-b31c-81c46787925c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model_load.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args_eval = TrainingArguments(\n",
        "    output_dir='./results_eval',\n",
        "    report_to=\"none\",  # Desactivar wandb\n",
        ")"
      ],
      "metadata": {
        "id": "j5bgFFkR_SvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Npz6Oc-xSD"
      },
      "outputs": [],
      "source": [
        "trainer_eval = Trainer(\n",
        "    model=model_load,\n",
        "    args=training_args_eval,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "9bOCvZ0MBiuS",
        "outputId": "0397e4f1-30a9-48c1-deb9-6fbff985d131"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3100' max='3100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3100/3100 02:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados de evaluación: {'eval_loss': 0.36632803082466125, 'eval_model_preparation_time': 0.0067, 'eval_accuracy': 0.8380852522482558, 'eval_balanced_acc': 0.8334620224028648, 'eval_precision': (0.8202915228231684,), 'eval_recall': (0.7998129967274428,), 'eval_f1': 0.8099228329309284, 'eval_runtime': 126.4809, 'eval_samples_per_second': 196.053, 'eval_steps_per_second': 24.51}\n"
          ]
        }
      ],
      "source": [
        "# Evaluar el modelo en el conjunto de evaluación\n",
        "results_eval_load = trainer_eval.evaluate()\n",
        "\n",
        "# Imprimir los resultados para comprobar que son los mismos\n",
        "print(f\"Resultados de evaluación: {results_eval_load}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}